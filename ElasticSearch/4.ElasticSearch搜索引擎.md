本笔记分析研究对于ES的search功能的原理

## 一、查询分页

通过之前的学习，我们可以知道搜索时可以通过from和size字段来配置分页信息

```json
POST /ecommerce/product/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0,
  "size": 2
}
```

![1571034663141](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571034663141.png)

我们先进行结果分析，

- took：查询使用12毫秒
- timed_out：没有超时
- _shards：查询请求了多少个分片，成功请求多少个分片
- hits：命中数量，最大匹配分数，具体命中数据

当我们看数据时，发现_id为2的在前，\_id为1的在后，这是es底层分页导致的。

**es查询分页原理**：举例3个shard，3000条数据，查询from=100，size=10

1. 因为from100，size10，即需要100-109的数据
2. es协调节点向3个shard发出请求，要求获取**每个shard的0-109的数据**，**注意是0-109**
3. 每个shard接收到请求后，会创建一个`from+size`大小的`priority queue`，一个优先队列，将查询出的数据放入队列再全部返回给协调节点。
4. 协调节点获取到这些数据，总数据量为330条，将这些数据放到自己的`priority queue`，**然后对这些数据进行排序**
5. 排序后**将序号为100-109的数据返回给客户端**

这时我们会发现，如果数据量增加到30万条，而用户需要最后10条，那么es的协调节点需要**临时存储30万条数据且进行排序**，会导致大量资源耗费，所以对于ES的分页，要尽量避免**DEEP PAGING**的情况。

## 二、全域搜索

ES提供了一种query string的字段，可以将关键词分词再进行搜索，并且可以全域搜索，即不指定查询哪个field

```json
POST /ecommerce/product/_search
{
  "query":{
    "query_string": {
	"query": "gaolujie yagao"
    }
  }
}

GET /ecommerce/product/_search?q=gaolujie yagao
```

问题提出：不指定field，ES底层是如何处理并查询所有域呢？难道是对每个field都进行查询吗？

如果对每个field都进行一次查询，太繁琐且性能低，ES的底层不是这样的，它有一个元数据`_all field`，在建立索引保存document的时候，会讲所有域的值串成一个字符串并赋值给元数据_all field。

例如：

```json
{
  "name": "jack",
  "age": 26,
  "address": "guangzhou"
}
_all field = "jack 26 guangzhou"
```

当全域搜索的时候只需搜索`_all field`元数据即可

## 三、mapping

我们之前了解mapping就类似一张表的数据结构，定义了多个字段，我们回过头来再研究一下

**1）**在es里直接插入数据时`PUT shop/book/1`及数据信息时，es会自动建立索引、type和mapping

**2）mapping会根据数据自动定义field的数据类型**，如2018-01-01日期格式的数据类型为date，100数字格式的为long

**3）**不同的数据类型可能有的是**exact value精准匹配**，有的是**full text全文检索**。比如text就为全文检索，date就为精准匹配

**4）**exact value在建立倒排索引时，是**整个词**进行建立，full text是使用分词器**分词后**再对不同的词进行建立。所以在搜索时也不同

**5）**mapping的建立可以让**es自动建**，或者**手动设置**mapping的field，包括数据类型，分词器，是否存储，是否索引等等

**这里我们举个例子来看一看精准匹配与全文检索**

![1571043610271](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571043610271.png)

创建两条数据，website/article，因为是直接插入的，所以mapping是es自动创建的，我们看下mapping格式

![1571043677772](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571043677772.png)

可以看到author_id是long，post_date是date，和我们上面说的一样。

我们通过上面说的全域搜索query string进行查询一下试一试：

![1571043897206](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571043897206.png)

可以看到我们全域搜索2017可以查询出2条数据

![1571043986752](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571043986752.png)

如果我们指定域post_date查询，只能查到一条，为什么呢？

**全域搜索：查询的是\_all field的字段，其类型text属于全文检索，即对2017-01-01这个数据分词后再查询，所以有2条**

**指定域：查询的是post_date字段，其类型date属于精准搜索，即对日期没有分词，又因为es5.x之后的优化，所以能查出一条记录，其实在5.x之前的版本是一条都查不出来的。即只能用2017-01-01这个搜索关键词才能查出。**

## 四、Filter和Query

在前面已经学习了如何过滤数据。

![1571057595341](https://raw.githubusercontent.com/PAcee1/myNote/master/image/1571057595341.png)

这样一看，发现filter和query的功能好像差不多，能相互转化，那么到底应该用什么呢？

query：每次查询需要进行计算匹配值并排序，无法缓存结果

filter：每次只按搜索条件过滤，不排序计算，会缓存结果

这样一看，使用场景显而易见了，这里要说下，看着filter不计算，效率肯定比query高，其实不然，**在第一次查询时，query的效率可能还会比filter高，因为filter需要缓存结果，但是除了第一次查询，filter的速度比query快几十上百倍。**

## 五、ES的相关度评分

在进行查询操作时，前面介绍说排序默认是按_score分数来排的，且es底层的计算排序也是如此，那么到底是如何排序计算呢？就是我们要讲的相关度评分，TF/IDF（词频/逆向文档频率）

官方文档告诉我们，分数的由来主要有三个因素决定

### 5.1.词频（TF）

词频即词在文档中出现的频率，频率越高，权重越高，计算公式为：
$$
tf(td) = √frequency
$$
词`t`在文档`d`的频率是：该词在文档中出现次数的平方根

例如：搜索`hello world`

doc1：hello you, and world is very good
doc2：hello, how are you

那么分词后在doc1出现2次，doc2出现1次，即doc1分数高

如果不在意词在某个字段中出现的频次，而只在意是否出现过，则可以在字段映射中禁用词频统计：

```json
PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type":          "text",
          "index_options": "docs" 
        }
      }
    }
  }
}
```

设置其field的index_options为docs，即计算分数时不会再计算词频TF

### 5.2.逆向文档频率（IDF）

即词在总文档中出现的频率，频率越高，分数越低

$$
idf(t) = 1 + log ( numDocs / (docFreq + 1))
$$
 词 `t` 的逆向文档频率（ `idf` ）是：索引中文档数量除以所有包含该词的文档数，然后求其对数。

例如：搜索`hello world`

doc1：world is very good,bro（world在总document中出现1000次）
doc2：hello, how are you（hello在总）

因为doc1的出现次数更多，所以doc2的分数更高

### 5.3.字段长度归一值（flnorm）

Field-length norm：字段的长度越长，其分数越低
$$
norm(d) = 1 / √numTerms
$$
字段长度归一值（ `norm` ）是字段中词数平方根的倒数

例如：搜索`hello world`

doc1：world is very good,bro
doc2：hello, how are you

因为doc2的长度更短，所以doc2的分数更高

Norm和TF一样也可以禁用的

```json
PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type":          "text",
          "norms": { "enabled": false }
        }
      }
    }
  }
}
```

设置其field的norms为false，即计算分数时不会再计算Norm

## 六、SearchType

ES是分布式的全文检索系统，其特点就是分片存储数据，ES如何获取用户需要的数据且排序呢？ES搜索排序分为两步：

1）ES向5个分片发出请求，叫Scatter

2）5个分片独立搜索，将符合条件的数据返回，ES将数据集中起来再进行重新排序，返回给用户，即Gather

这样就会出现问题：

1）数量问题：用户需要10条数据，ES向5个分片发出前10条数据的请求，得到结果会有50条数据，ES再进行排序返回，用户就会获得50条数据，不符合请求数量。

2）排序问题：ES的排序是基于分片传来的分数的，即每个分片有不同的使用频率，举个例子：分片1的name字段的mike使用200次，allie使用100次，用户查询1条最高使用数据，当然分片1返回mike，这时分片2的name字段bob使用10次，jasper使用5次，就会返回bob，这样的话明显allie的使用频率更高。所以如果要解决这种情况，ES要先获取分片上频率，然后统一计算后再排序查询。

这两个问题，估计ES也没有什么较好的解决方法，最终把选择的权利交给用户，方法就是在搜索的时候指定query type。

有三种SearchType：

- Query and fetch：即ES请求所有分片，返回n*5的数据整合排序，就会出现上面的问题，返回数量是用户要求的n倍。这种方法以及被弃用了
- query then fetch：ES请求所有分片，获取排名相关的信息，而不是数据，es获取后进行计算然后再根据计算结果向不同分片请求数据，这样可以解决上面数量问题和排序问题。默认使用，也最常用
- DFS query then fetch：同样多了初始化散发过程。

## 七、零停机重建索引

> **前提条件：Java应用中使用的别名查询而不是索引名**

经过之前的学习知道field属性一旦创建就不能被修改，比如创建时是text，你不能后面再修改成date类型，那么我们模拟一下真实生产场景：

### 7.1.问题的提出

1）创建document，使用dynamic mapping，但是不小心把title的类型设置成date了，实际是text类型

```json
PUT my_index/my_type/1
{
  "title":"2019-01-01",
  "content":"zero gogo"
}
```

![1571122209687](C:\Users\S1\AppData\Roaming\Typora\typora-user-images\1571122209687.png)

2）向索引添加text类型的title数据，因为类型不匹配报错

![1571122263592](C:\Users\S1\AppData\Roaming\Typora\typora-user-images\1571122263592.png)

3）因为不能直接修改，所以需要重建索引

### 7.2.问题的解决

1）创建索引，配置正确的field类型

```json
PUT /new_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": {
          "type": "text"
        }，
		"content":{
			"type":"text"
		}
      }
    }
  }
}
```

2）设置别名，将新索引加入到旧索引的别名上（Java程序使用的是别名）

```json
POST /_aliases
{
    "actions": [
        { "add": { "index": "new_index", "alias": "alias_index" }},
        { "add": { "index": "my_index", "alias": "alias_index" }}
    ]
}
```

3）使用reindex api同步索引数据

```json
POST _reindex
{
  "source": {
    "index": "my_index"
  },
  "dest": {
    "index": "new_index"
  }
}
```

4）查看新索引数据是否同步成功

![1571123565039](C:\Users\S1\AppData\Roaming\Typora\typora-user-images\1571123565039.png)

同步成功

5）删除别名中的旧索引

```js
POST /_aliases
{
    "actions": [
        { "remove": { "index": "my_index_v1", "alias": "my_index" }},
        { "add":    { "index": "my_index_v2", "alias": "my_index" }}
    ]
}
```